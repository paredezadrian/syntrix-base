---
description: Testing standards for Apply Intelligently.
---

# Testing Standards

## Test Organization
- Use `pytest` as the testing framework
- Organize tests by functionality (shapes, determinism, CLI)
- Use descriptive test function names that explain what is being tested
- Group related tests in classes when appropriate

## Model Testing
- **Shape Tests**: Verify all model outputs have expected dimensions
- **Parameter Counts**: Test that parameter counts match expected values
- **Forward Pass**: Ensure models can process input without errors
- **Gradient Flow**: Verify gradients can be computed and backpropagated

## Determinism Testing
- **Seed Consistency**: Test that same seed produces identical results
- **Thread Independence**: Verify results are consistent across thread counts
- **Device Independence**: Test results are consistent on CPU
- **Reproducibility**: Ensure training curves are identical with fixed seeds

## CLI Testing
- **Command Parsing**: Test all command-line arguments and options
- **Config Loading**: Verify YAML configuration files are loaded correctly
- **Error Handling**: Test graceful handling of invalid inputs
- **Integration**: Test end-to-end CLI functionality

## Data Pipeline Testing
- **Dataset Loading**: Test loading of sample datasets
- **Tokenization**: Verify tokenizer produces expected outputs
- **Batching**: Test data collation and batching logic
- **Memory Mapping**: Test efficient file loading with mmap

## Performance Testing
- **Throughput**: Measure tokens per second for training
- **Memory Usage**: Monitor memory consumption during training
- **Convergence**: Test that models converge to reasonable loss values
- **Benchmarks**: Include performance benchmarks for CPU targets

## Test Data
- Use small, synthetic datasets for fast testing
- Include TinyShakespeare and Text8-mini as test datasets
- Mock external dependencies when appropriate
- Use fixtures for common test setup
