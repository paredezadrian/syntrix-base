model: ssm_mini
vocab_size: 128
block_size: 128
d_model: 256
depth: 4

optim:
  lr: 3.0e-3
  weight_decay: 0.05
  betas: [0.9, 0.95]

schedule:
  type: cosine
  warmup_steps: 50

train:
  batch_size: 32
  microbatch: 1
  grad_accum: 64
  dtype: float32
  threads: 4


